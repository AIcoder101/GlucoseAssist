import pandas as pd
from numpy import array
import numpy as np
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Flatten 
from keras.layers.convolutional import Conv1D
from keras.layers.convolutional import MaxPooling1D
import tensorflow as tf
import math
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_absolute_percentage_error
from sklearn.metrics import mean_squared_log_error
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import r2_score

#importing of the timeseries data from AUC excel

#importng all other parameters
xls1 = pd.read_excel('/content/Traindata.xlsx', 'P02' )

#automatically creating an dtasheet of organized data for direct classifier input

#rownum is associated with each meal
def create_array(rownum):
  list1 = []
  #iterating theough the 120 cgm points in the dataset
  for i in range(8,128): 
    list1 = list1 + [xls1.iat[rownum, i]]
  def split_sequence(sequence, n_steps_in, n_steps_out):
    X, y = list(), list()
    for i in range(0, len(sequence), 15):
      # find the end of this pattern
      end_ix = i + n_steps_in     
      # check if we are beyond the sequence
      if end_ix > len(sequence)-5: 
        break
      # gather input and output parts of the pattern
      seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:i+n_steps_in +n_steps_out]
      X.append(seq_x)
      y.append(seq_y)
    return array(X), array(y)
    #splitting into my ideal size of 60 min input and 30 min output
  X, y = split_sequence(list1, 30, 15)
  df = pd.DataFrame(columns=['X parameters', 'Y parameters'])
  for i in range(len(X)):
    df.loc[len(df.index)] = (X[i], y[i])
    #creating the colums for dataframe of training CGM data, and testing CGM data
  data = pd.DataFrame(X, columns = ['T1','T2','T3', 'T4', 'T5','T6','T7', 'T8', 'T9','T10', 'T11','T12','T13', 'T14', 'T15','T16','T17', 'T18', 'T19','T20', 'T21','T22','T23', 'T24', 'T25','T26','T27', 'T28', 'T29','T30'])
  data1 = pd.DataFrame(y, columns = ['G1','G2','G3', 'G4','G5', 'G6','G7','G8', 'G9', 'G10','G11','G12', 'G13', 'G14','G15'])
  return (data, data1)

#initializing a basic datframe with first row
data, data1 = create_array(0)
numofiter = 6
df1 = pd.DataFrame({'ch' : [xls1.iat[0, 0]] * numofiter , 'fat' : [xls1.iat[0, 1]] * numofiter, 'fiber' : [xls1.iat[0, 2]] * numofiter, 'gl' : [xls1.iat[0, 3]] * numofiter, 'p1' : [xls1.iat[0, 4]] * numofiter, 'p2' : [xls1.iat[0, 5]] * numofiter, 'p3' : [xls1.iat[0, 6]] * numofiter, 'p4' : [xls1.iat[0, 7]] * numofiter})
ans = pd.concat([df1, data, data1], axis = 1)
ans.insert(0, "Time", [0, 30, 60, 90, 120, 150] )
#for loop iterating though the rest of the data and importing the fat, fibe, glucose, etc.
for i in range(1,43):
  data, data1 = create_array(i)
  df1 = pd.DataFrame({'Time' : [0, 30, 60, 90, 120, 150], 'ch' : [xls1.iat[i, 0]] * numofiter , 'fat' : [xls1.iat[i, 1]] * numofiter, 'fiber' : [xls1.iat[i, 2]] * numofiter, 'gl' : [xls1.iat[i, 3]] * numofiter, 'p1' : [xls1.iat[i, 4]] * numofiter, 'p2' : [xls1.iat[i, 5]] * numofiter, 'p3' : [xls1.iat[i, 6]] * numofiter, 'p4' : [xls1.iat[i, 7]] * numofiter})
  #adding all three data frames/columns into the one dataframe
  ans1 = pd.concat([df1, data, data1], axis = 1)
  ans = pd.concat([ans, ans1], axis = 0)

ans

import matplotlib.pyplot as plt


#This function takes in the reference values and the prediction values as lists and returns a list with each index corresponding to the total number
#of points within that zone (0=A, 1=B, 2=C, 3=D, 4=E) and the plot
def clarke_error_grid(ref_values, pred_values, title_string):

    #Checking to see if the lengths of the reference and prediction arrays are the same
    assert (len(ref_values) == len(pred_values)), "Unequal number of values (reference : {}) (prediction : {}).".format(len(ref_values), len(pred_values))

    #Checks to see if the values are within the normal physiological range, otherwise it gives a warning
    if max(ref_values) > 22.2 or max(pred_values) > 22.2:
        print ("Input Warning: the maximum reference value {} or the maximum prediction value {} exceeds the normal physiological range of glucose (<22.2 mmol/l).".format(max(ref_values), max(pred_values)))
    if min(ref_values) < 0 or min(pred_values) < 0:
        print ("Input Warning: the minimum reference value {} or the minimum prediction value {} is less than 0 mmol/l.".format(min(ref_values),  min(pred_values)))

    #Clear plot
    plt.clf()

    #Set up plot
    plt.scatter(ref_values, pred_values, marker='o', color='c')
    plt.title(title_string + " Clarke Error Grid: Patient 3")
    plt.xlabel("Reference Concentration (mmol/l)")
    plt.ylabel("Prediction Concentration (mmol/l)")
    plt.xticks([0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22])
    plt.yticks([0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22])
    plt.gca().set_facecolor('white')

    #Set axes lengths
    plt.gca().set_xlim([0, 22.2])
    plt.gca().set_ylim([0, 22.2])
    plt.gca().set_aspect((44.4)/(44.4))

    #Plot zone lines
    plt.plot([0,22], [0,22], ':', c='black')                      #Theoretical 45 regression line
    plt.plot([0, 3.2375], [3.885, 3.885], '-', c='black')
    #plt.plot([3.2375, 320], [3.885, 22.2], '-', c='black')
    plt.plot([3.2375, 22.2/1.2], [3.885, 22.2], '-', c='black')           #Replace 320 with 400/1.2 because 100*(400 - 400/1.2)/(400/1.2) =  20% error
    plt.plot([3.885, 3.885], [4.662, 22.2],'-', c='black')
    plt.plot([0, 3.885], [9.99, 9.99], '-', c='black')
    plt.plot([3.885, 16.095],[9.99, 22.2],'-', c='black')
    # plt.plot([3.885, 3.885], [0, 3.2375], '-', c='black')
    plt.plot([3.885, 3.885], [0, 3.108], '-', c='black')                     #Replace 175.3 with 56 because 100*abs(56-70)/70) = 20% error
    # plt.plot([3.885, 22.2],[3.2375, 17.76],'-', c='black')
    plt.plot([3.885, 22.2], [3.108, 17.76],'-', c='black')
    plt.plot([9.99, 9.99], [0, 3.885], '-', c='black')
    plt.plot([9.99, 22.2], [3.885, 3.885], '-', c='black')
    plt.plot([13.32, 13.32], [3.885, 9.99],'-', c='black')
    plt.plot([13.32, 22.2], [9.99, 9.99], '-', c='black')
    plt.plot([7.215, 9.99], [0, 3.885], '-', c='black')

    #Add zone titles
    plt.text(1.66, 0.833, "A", fontsize=15)
    plt.text(20.55, 20.55, "A", fontsize=15)
    plt.text(20.55, 14.44, "B", fontsize=15)
    plt.text(15.55, 20.55, "B", fontsize=15)
    plt.text(8.88, 20.55, "C", fontsize=15)
    plt.text(8.88, 0.833, "C", fontsize=15)
    plt.text(1.66, 7.77, "D", fontsize=15)
    plt.text(20.55, 6.66, "D", fontsize=15)
    plt.text(1.66, 20.55, "E", fontsize=15)
    plt.text(20.55, 0.833, "E", fontsize=15)

    #Statistics from the data
    zone = [0] * 5
    for i in range(len(ref_values)):
        if (ref_values[i] <= 3.885 and pred_values[i] <= 3.885) or (pred_values[i] <= 1.2*ref_values[i] and pred_values[i] >= 0.8*ref_values[i]):
            zone[0] += 1    #Zone A

        elif (ref_values[i] >= 9.99 and pred_values[i] <= 3.885) or (ref_values[i] <= 70 and pred_values[i] >= 9.99):
            zone[4] += 1    #Zone E

        elif ((ref_values[i] >= 3.885 and ref_values[i] <= 16.095) and pred_values[i] >= ref_values[i] + 6.105) or ((ref_values[i] >= 7.215 and ref_values[i] <= 9.99) and (pred_values[i] <= (7/5)*ref_values[i] - 10.101)):
            zone[2] += 1    #Zone C
        elif (ref_values[i] >= 13.32 and (pred_values[i] >= 3.885 and pred_values[i] <= 5.55)) or (ref_values[i] <= 3.2373 and pred_values[i] <= 9.99 and pred_values[i] >= 3.885) or ((ref_values[i] >= 3.2373 and ref_values[i] <= 3.885) and pred_values[i] >= (6/5)*ref_values[i]):
            zone[3] += 1    #Zone D
        else:
            zone[1] += 1    #Zone B

    return zone

#testing 5 trials for current file

import matplotlib.pyplot as plt
import matplotlib.pyplot as plt1

df = ans

def trials (input):
  X = df[['Time', 'ch', 'fat', 'fiber', 'gl', 'p1', 'p2', 'p3', 'p4','T1','T2','T3', 'T4', 'T5','T6','T7', 'T8', 'T9','T10', 'T11','T12','T13', 'T14', 'T15','T16','T17', 'T18', 'T19','T20', 'T21','T22','T23', 'T24', 'T25','T26','T27', 'T28', 'T29','T30']].to_numpy()
  y = df[['G1','G2','G3', 'G4','G5', 'G6','G7','G8', 'G9', 'G10','G11','G12', 'G13', 'G14','G15']].to_numpy()
  X = X.reshape((X.shape[0], X.shape[1], 1))

  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
  # univariate cnn example
  # define model
  model = Sequential()
  n_steps1 = 1
  model.add(Conv1D(filters=240, kernel_size=2, activation='relu', input_shape=(X.shape[1], n_steps1,)))

  model.add(MaxPooling1D(pool_size=2))
  model.add(Flatten())
  model.add(Dense(50, activation='relu'))
  model.add(Dense(15))
  model.compile(optimizer='adam', loss='mse')
  # fit model
  #print(model.summary())

  model.fit(X_train, y_train, epochs=100, verbose=0)
  # demonstrate prediction
  x_input = X_test
  yhat = model.predict(X_test, verbose=0)

  yhat = np.around(yhat, decimals=1)

  predlist =[]
  for x in yhat:
    for y in x:
      predlist.append(y)

  testlist =[]
  for x in y_test:
    for y in x:
      testlist.append(y)
  #clarke_error_grid(testlist, predlist,' ')

  x1  = []
  for i in range(1,len(testlist)+1) :
    x1.append(i)

  x2  = []
  for i in range(1,len(testlist)+1) :
    x2.append(i)
    
  # line 1 points
  y1 = testlist
  # plotting the line 1 points 
  plt1.plot(x1, y1, label = "actual", color = 'b')
    
  # line 2 points
  y2 = predlist
  # plotting the line 2 points 
  plt1.plot(x2, y2, label = "predicted", color = 'c')
    
  # naming the x axis
  plt1.xlabel('Time (minutes)')
  # naming the y axis
  plt1.ylabel('Glucose levels (mmol/L)')
  # giving a title to my graph
  plt1.title('Glucose Levels: Patient 5')
  plt1.axhline(y = 7.8, color = 'orange', linestyle = '-')
  plt1.axhline(y = 3.3, color = 'orange', linestyle = '-')
    
  # show a legend on the plot
  plt1.legend()
    
  # function to show the plot
  plt1.show()

  MSE = mean_squared_error(y_test, yhat)
  RMSE = math.sqrt(MSE)
  MAE = mean_absolute_error(y_test,yhat)
  rmspe = (np.sqrt(np.mean(np.square((y_test - yhat) / y_test)))) * 100
  MAPE = mean_absolute_percentage_error(y_test, yhat)
  MSLE = mean_squared_log_error(y_test, yhat)
  #CS= cosine_similarity(y_test, yhat)
  h = tf.keras.losses.Huber()
  huber = h(y_test, yhat).numpy()
  l = tf.keras.losses.LogCosh()
  log = l(y_test, yhat).numpy()
  r2=  r2_score(y_test, yhat)
  data = [MSE, RMSE, MAE, rmspe, MAPE, MSLE, huber, log, r2 ]
  df2 = pd.DataFrame(data, columns=[('trial ' + str(input))])

  
  return df2


#initializing a basic datframe with first row
df1 = pd.DataFrame([" Mean Square Error:", "Root Mean Square Error:","Mean Absolute Error:", "Root Mean Square Percent Error:" , "Mean Absolute Percent Error:", "Mean Square Logarithmic Error:", "Huber Loss:", "LogCosh:", "R^2 value:" ])
#for loop iterating though the rest of the data and importing the fat, fibe, glucose, etc.
trialtest = df1
for j in range(1,6):
  data = trials(j)
  #adding all three data frames/columns into the one dataframe
  trialtest = pd.concat([trialtest, data], axis = 1)
  #saving to excel
trialtest.to_excel('output.xlsx')
trialtest

#figure out clarke error gird
#clarke_error_grid(testlist, predlist,' ')

# univariate cnn lstm example
from numpy import array
from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers import TimeDistributed
from keras.layers.convolutional import Conv1D
from keras.layers.convolutional import MaxPooling1D
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers import Dropout, BatchNormalization, Activation
from keras import optimizers

df = pd.read_csv("/content/AllPatients.csv")

import numpy as np

X = df[['Time', 'ch', 'fat', 'fiber', 'gl', 'p1', 'p2', 'p3', 'p4','T1','T2','T3', 'T4', 'T5','T6','T7', 'T8', 'T9','T10', 'T11','T12','T13', 'T14', 'T15','T16','T17', 'T18', 'T19','T20', 'T21','T22','T23', 'T24', 'T25','T26','T27', 'T28', 'T29','T30']].to_numpy()
y = df[['G1','G2','G3', 'G4','G5', 'G6','G7','G8', 'G9', 'G10','G11','G12', 'G13', 'G14','G15']].to_numpy()
X = X.reshape((X.shape[0], X.shape[1], 1))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)
# univariate cnn example
# define model

model = Sequential()
n_steps1 = 1
model.add(Conv1D(filters=240, kernel_size=2, activation='relu', input_shape=(X.shape[1], n_steps1,)))

model.add(MaxPooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(50, activation='relu'))
model.add(Dense(15))
model.compile(optimizer='adam', loss='mse')
# fit model
#print(model.summary())

model.fit(X_train, y_train, epochs=100, verbose=0)
# demonstrate prediction
x_input = X_test
yhat = model.predict(X_test, verbose=0)

yhat = np.around(yhat, decimals=1)
